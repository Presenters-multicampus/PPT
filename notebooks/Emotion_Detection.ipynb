{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Sample_Pic_OD/fer2013.csv')\n",
    "train = dataset[['emotion','pixels']][:28709]\n",
    "val = dataset[['emotion','pixels']][28709:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 2), (7178, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9d920ca8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train['pixels'][0]\n",
    "img = np.array(img.split(' ')).reshape(48,-1).astype('float')\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',\\\n",
    "            6:'Neutral'}\n",
    "# just save one file for test\n",
    "cv2.imwrite('../fer2013/train/{}/{}.jpg'.format(label_map[train['emotion'][0]], 1), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',\\\n",
    "            6:'Neutral'}\n",
    "# for num, i in enumerate(train.index):\n",
    "#     img = train['pixels'][i]\n",
    "#     img = np.array(img.split(' ')).astype('float').reshape(48,-1)\n",
    "#     label = train['emotion'][i]\n",
    "#     cv2.imwrite('../fer2013/train/{}/{}.jpg'.format(label_map[label], num), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num, i in enumerate(val.index):\n",
    "#     img = val['pixels'][i]\n",
    "#     img = np.array(img.split(' ')).astype('float').reshape(48,-1)\n",
    "#     label = val['emotion'][i]\n",
    "#     cv2.imwrite('../fer2013/validation/{}/{}.jpg'.format(label_map[label], num), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 512\n",
    "\n",
    "train_data_dir = '../fer2013/train'\n",
    "validation_data_dir = '../fer2013/validation'\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 30,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 7)           903       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 7)           791       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 241,950\n",
      "Trainable params: 241,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001),input_shape=(48,48,1)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(7, kernel_size=(1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# # model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(7, kernel_size=(4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or we can just load pretrained model\n",
    "# model = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(img_rows,img_cols,3), alpha=1.0,\\\n",
    "#                         include_top=False, weights='imagenet', input_tensor=None,\\\n",
    "#                                             pooling=None, classes=num_classes)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "56/56 [==============================] - 15s 260ms/step - loss: 1.8905 - acc: 0.2652 - val_loss: 1.8840 - val_acc: 0.2705\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27051, saving model to ../emotion_detector_models/model_v6_1.hdf5\n",
      "Epoch 2/150\n",
      "56/56 [==============================] - 14s 256ms/step - loss: 1.8884 - acc: 0.2671 - val_loss: 1.8712 - val_acc: 0.2732\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.27051 to 0.27318, saving model to ../emotion_detector_models/model_v6_2.hdf5\n",
      "Epoch 3/150\n",
      "56/56 [==============================] - 14s 256ms/step - loss: 1.8900 - acc: 0.2642 - val_loss: 1.8593 - val_acc: 0.2697\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.27318\n",
      "Epoch 4/150\n",
      "56/56 [==============================] - 14s 255ms/step - loss: 1.8869 - acc: 0.2667 - val_loss: 1.8826 - val_acc: 0.2688\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.27318\n",
      "Epoch 5/150\n",
      "56/56 [==============================] - 14s 257ms/step - loss: 1.8890 - acc: 0.2609 - val_loss: 1.8573 - val_acc: 0.2634\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.27318\n",
      "Epoch 6/150\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.8841 - acc: 0.2689 - val_loss: 1.8598 - val_acc: 0.2781\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.27318 to 0.27813, saving model to ../emotion_detector_models/model_v6_6.hdf5\n",
      "Epoch 7/150\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.8822 - acc: 0.2716 - val_loss: 1.8843 - val_acc: 0.2784\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.27813 to 0.27843, saving model to ../emotion_detector_models/model_v6_7.hdf5\n",
      "Epoch 8/150\n",
      "56/56 [==============================] - 14s 254ms/step - loss: 1.8825 - acc: 0.2674 - val_loss: 1.8426 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.27843\n",
      "Epoch 9/150\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.8800 - acc: 0.2708 - val_loss: 1.9091 - val_acc: 0.2769\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.27843\n",
      "Epoch 10/150\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.8783 - acc: 0.2695 - val_loss: 1.8586 - val_acc: 0.2756\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.27843\n",
      "Epoch 11/150\n",
      "56/56 [==============================] - 14s 252ms/step - loss: 1.8723 - acc: 0.2769 - val_loss: 1.8254 - val_acc: 0.2726\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.27843\n",
      "Epoch 12/150\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.8723 - acc: 0.2730 - val_loss: 1.8421 - val_acc: 0.2714\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.27843\n",
      "Epoch 13/150\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.8674 - acc: 0.2718 - val_loss: 1.8599 - val_acc: 0.2873\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.27843 to 0.28728, saving model to ../emotion_detector_models/model_v6_13.hdf5\n",
      "Epoch 14/150\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.8650 - acc: 0.2740 - val_loss: 1.8514 - val_acc: 0.2907\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.28728 to 0.29073, saving model to ../emotion_detector_models/model_v6_14.hdf5\n",
      "Epoch 15/150\n",
      "56/56 [==============================] - 14s 256ms/step - loss: 1.8551 - acc: 0.2795 - val_loss: 1.7959 - val_acc: 0.2912\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.29073 to 0.29118, saving model to ../emotion_detector_models/model_v6_15.hdf5\n",
      "Epoch 16/150\n",
      "56/56 [==============================] - 14s 259ms/step - loss: 1.8549 - acc: 0.2817 - val_loss: 1.8859 - val_acc: 0.3019\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.29118 to 0.30190, saving model to ../emotion_detector_models/model_v6_16.hdf5\n",
      "Epoch 17/150\n",
      "56/56 [==============================] - 15s 268ms/step - loss: 1.8517 - acc: 0.2833 - val_loss: 1.8148 - val_acc: 0.2994\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.30190\n",
      "Epoch 18/150\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.8480 - acc: 0.2839 - val_loss: 1.8465 - val_acc: 0.2948\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.30190\n",
      "Epoch 19/150\n",
      "56/56 [==============================] - 14s 250ms/step - loss: 1.8484 - acc: 0.2857 - val_loss: 1.8143 - val_acc: 0.3017\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.30190\n",
      "Epoch 20/150\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 1.8396 - acc: 0.2883 - val_loss: 1.8095 - val_acc: 0.3083\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.30190 to 0.30828, saving model to ../emotion_detector_models/model_v6_20.hdf5\n",
      "Epoch 21/150\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.8416 - acc: 0.2864 - val_loss: 1.7951 - val_acc: 0.3123\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.30828 to 0.31233, saving model to ../emotion_detector_models/model_v6_21.hdf5\n",
      "Epoch 22/150\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 1.8333 - acc: 0.2945 - val_loss: 1.8635 - val_acc: 0.3116\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.31233\n",
      "Epoch 23/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.8299 - acc: 0.2920 - val_loss: 1.7980 - val_acc: 0.3174\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.31233 to 0.31743, saving model to ../emotion_detector_models/model_v6_23.hdf5\n",
      "Epoch 24/150\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 1.8248 - acc: 0.2961 - val_loss: 1.7522 - val_acc: 0.3117\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.31743\n",
      "Epoch 25/150\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 1.8294 - acc: 0.2935 - val_loss: 1.7717 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.31743 to 0.32628, saving model to ../emotion_detector_models/model_v6_25.hdf5\n",
      "Epoch 26/150\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 1.8189 - acc: 0.2977 - val_loss: 1.7729 - val_acc: 0.3099\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.32628\n",
      "Epoch 27/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.8224 - acc: 0.2967 - val_loss: 1.7450 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.32628\n",
      "Epoch 28/150\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 1.8131 - acc: 0.3015 - val_loss: 1.7800 - val_acc: 0.3123\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.32628\n",
      "Epoch 29/150\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.8126 - acc: 0.3016 - val_loss: 1.7979 - val_acc: 0.3252\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.32628\n",
      "Epoch 30/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.8076 - acc: 0.3043 - val_loss: 1.8509 - val_acc: 0.3251\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.32628\n",
      "Epoch 31/150\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 1.8063 - acc: 0.3008 - val_loss: 1.7705 - val_acc: 0.3189\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.32628\n",
      "Epoch 32/150\n",
      "56/56 [==============================] - 14s 257ms/step - loss: 1.8064 - acc: 0.3035 - val_loss: 1.7828 - val_acc: 0.3306\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.32628 to 0.33063, saving model to ../emotion_detector_models/model_v6_32.hdf5\n",
      "Epoch 33/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.8020 - acc: 0.3055 - val_loss: 1.7436 - val_acc: 0.3308\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.33063 to 0.33078, saving model to ../emotion_detector_models/model_v6_33.hdf5\n",
      "Epoch 34/150\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 1.8011 - acc: 0.3085 - val_loss: 1.7317 - val_acc: 0.3206\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.33078\n",
      "Epoch 35/150\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 1.7964 - acc: 0.3095 - val_loss: 1.7722 - val_acc: 0.3356\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.33078 to 0.33558, saving model to ../emotion_detector_models/model_v6_35.hdf5\n",
      "Epoch 36/150\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.7972 - acc: 0.3080 - val_loss: 1.7294 - val_acc: 0.3317\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.33558\n",
      "Epoch 37/150\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.7875 - acc: 0.3121 - val_loss: 1.7339 - val_acc: 0.3302\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.33558\n",
      "Epoch 38/150\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 1.7903 - acc: 0.3101 - val_loss: 1.7256 - val_acc: 0.3332\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.33558\n",
      "Epoch 39/150\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.7862 - acc: 0.3135 - val_loss: 1.7150 - val_acc: 0.3290\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.33558\n",
      "Epoch 40/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 14s 244ms/step - loss: 1.7892 - acc: 0.3094 - val_loss: 1.7632 - val_acc: 0.3350\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.33558\n",
      "Epoch 41/150\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 1.7818 - acc: 0.3179 - val_loss: 1.7704 - val_acc: 0.3305\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.33558\n",
      "Epoch 42/150\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.7808 - acc: 0.3145 - val_loss: 1.7241 - val_acc: 0.3353\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.33558\n",
      "Epoch 43/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7851 - acc: 0.3153 - val_loss: 1.7437 - val_acc: 0.3303\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.33558\n",
      "Epoch 44/150\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 1.7782 - acc: 0.3152 - val_loss: 1.6914 - val_acc: 0.3410\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.33558 to 0.34098, saving model to ../emotion_detector_models/model_v6_44.hdf5\n",
      "Epoch 45/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7809 - acc: 0.3166 - val_loss: 2.0548 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.34098\n",
      "Epoch 46/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7802 - acc: 0.3157 - val_loss: 1.7348 - val_acc: 0.3355\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.34098\n",
      "Epoch 47/150\n",
      "56/56 [==============================] - 15s 265ms/step - loss: 1.7772 - acc: 0.3134 - val_loss: 1.7148 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.34098 to 0.34293, saving model to ../emotion_detector_models/model_v6_47.hdf5\n",
      "Epoch 48/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7722 - acc: 0.3179 - val_loss: 1.7559 - val_acc: 0.3392\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.34293\n",
      "Epoch 49/150\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 1.7708 - acc: 0.3196 - val_loss: 1.7143 - val_acc: 0.3273\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.34293\n",
      "Epoch 50/150\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 1.7724 - acc: 0.3214 - val_loss: 1.6710 - val_acc: 0.3471\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.34293 to 0.34713, saving model to ../emotion_detector_models/model_v6_50.hdf5\n",
      "Epoch 51/150\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.7670 - acc: 0.3190 - val_loss: 1.7224 - val_acc: 0.3402\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.34713\n",
      "Epoch 52/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.7709 - acc: 0.3205 - val_loss: 1.7131 - val_acc: 0.3455\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.34713\n",
      "Epoch 53/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.7630 - acc: 0.3228 - val_loss: 1.7170 - val_acc: 0.3359\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.34713\n",
      "Epoch 54/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.7626 - acc: 0.3219 - val_loss: 1.6840 - val_acc: 0.3473\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.34713 to 0.34728, saving model to ../emotion_detector_models/model_v6_54.hdf5\n",
      "Epoch 55/150\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 1.7608 - acc: 0.3237 - val_loss: 1.6861 - val_acc: 0.3503\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.34728 to 0.35029, saving model to ../emotion_detector_models/model_v6_55.hdf5\n",
      "Epoch 56/150\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 1.7630 - acc: 0.3257 - val_loss: 1.7642 - val_acc: 0.3336\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.35029\n",
      "Epoch 57/150\n",
      "56/56 [==============================] - 13s 235ms/step - loss: 1.7630 - acc: 0.3212 - val_loss: 1.7522 - val_acc: 0.3459\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.35029\n",
      "Epoch 58/150\n",
      "56/56 [==============================] - 13s 232ms/step - loss: 1.7583 - acc: 0.3284 - val_loss: 1.7545 - val_acc: 0.3398\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.35029\n",
      "Epoch 59/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.7624 - acc: 0.3240 - val_loss: 1.7011 - val_acc: 0.3485\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.35029\n",
      "Epoch 60/150\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.7567 - acc: 0.3274 - val_loss: 1.4367 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.35029\n",
      "Epoch 61/150\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.7538 - acc: 0.3288 - val_loss: 1.6766 - val_acc: 0.3549\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.35029 to 0.35491, saving model to ../emotion_detector_models/model_v6_61.hdf5\n",
      "Epoch 62/150\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 1.7570 - acc: 0.3269 - val_loss: 1.6762 - val_acc: 0.3522\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.35491\n",
      "Epoch 63/150\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.7476 - acc: 0.3322 - val_loss: 1.6824 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.35491 to 0.35584, saving model to ../emotion_detector_models/model_v6_63.hdf5\n",
      "Epoch 64/150\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.7526 - acc: 0.3257 - val_loss: 1.7238 - val_acc: 0.3513\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.35584\n",
      "Epoch 65/150\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.7547 - acc: 0.3288 - val_loss: 1.7213 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.35584\n",
      "Epoch 66/150\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.7436 - acc: 0.3363 - val_loss: 1.6815 - val_acc: 0.3455\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.35584\n",
      "Epoch 67/150\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 1.7491 - acc: 0.3320 - val_loss: 1.6963 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.35584 to 0.36169, saving model to ../emotion_detector_models/model_v6_67.hdf5\n",
      "Epoch 68/150\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.7538 - acc: 0.3293 - val_loss: 1.6807 - val_acc: 0.3578\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.36169\n",
      "Epoch 69/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7431 - acc: 0.3339 - val_loss: 1.6513 - val_acc: 0.3507\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.36169\n",
      "Epoch 70/150\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.7457 - acc: 0.3357 - val_loss: 1.6689 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.36169\n",
      "Epoch 71/150\n",
      "56/56 [==============================] - 13s 235ms/step - loss: 1.7408 - acc: 0.3357 - val_loss: 1.6835 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.36169\n",
      "Epoch 72/150\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 1.7424 - acc: 0.3348 - val_loss: 1.6612 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.36169\n",
      "Epoch 73/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7374 - acc: 0.3372 - val_loss: 1.7026 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.36169\n",
      "Epoch 74/150\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.7375 - acc: 0.3391 - val_loss: 1.6851 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.36169\n",
      "Epoch 75/150\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 1.7386 - acc: 0.3368 - val_loss: 1.5928 - val_acc: 0.3657\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.36169 to 0.36574, saving model to ../emotion_detector_models/model_v6_75.hdf5\n",
      "Epoch 76/150\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 1.7334 - acc: 0.3378 - val_loss: 1.7335 - val_acc: 0.3658\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.36574 to 0.36579, saving model to ../emotion_detector_models/model_v6_76.hdf5\n",
      "Epoch 77/150\n",
      "56/56 [==============================] - 15s 261ms/step - loss: 1.7299 - acc: 0.3423 - val_loss: 1.6701 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.36579\n",
      "Epoch 78/150\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 1.7307 - acc: 0.3411 - val_loss: 1.6420 - val_acc: 0.3653\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.36579\n",
      "Epoch 79/150\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.7328 - acc: 0.3385 - val_loss: 1.7045 - val_acc: 0.3626\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.36579\n",
      "Epoch 80/150\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.7303 - acc: 0.3443 - val_loss: 1.6669 - val_acc: 0.3596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00080: val_acc did not improve from 0.36579\n",
      "Epoch 81/150\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 1.7367 - acc: 0.3394 - val_loss: 1.7276 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.36579\n",
      "Epoch 82/150\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 1.7302 - acc: 0.3440 - val_loss: 1.6765 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.36579\n",
      "Epoch 83/150\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.7304 - acc: 0.3401 - val_loss: 1.6705 - val_acc: 0.3666\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.36579 to 0.36664, saving model to ../emotion_detector_models/model_v6_83.hdf5\n",
      "Epoch 84/150\n",
      "38/56 [===================>..........] - ETA: 3s - loss: 1.7225 - acc: 0.3455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fdb25d83193e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             validation_steps=nb_validation_samples // batch_size)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# plot_model_history(model_info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(\"../emotion_detector_models/model_v6_{epoch}.hdf5\")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                             monitor='val_acc',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             mode='max')\n",
    "callbacks = [checkpoint]\n",
    "model.compile(loss='categorical_crossentropy',\\\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['acc'])\n",
    "nb_train_samples = train.shape[0]\n",
    "nb_validation_samples = val.shape[0]\n",
    "epochs = 150\n",
    "model_info = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# plot_model_history(model_info)\n",
    "# model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/KTH/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "56/56 [==============================] - 40s 714ms/step - loss: 1.6678 - acc: 0.3745 - val_loss: 1.6033 - val_acc: 0.3796\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.37960, saving model to ../emotion_detector_models/model_v6_final.hdf5\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.6671 - acc: 0.3734 - val_loss: 1.6015 - val_acc: 0.3942\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37960 to 0.39424, saving model to ../emotion_detector_models/model_v6_final.hdf5\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.6647 - acc: 0.3739 - val_loss: 1.6386 - val_acc: 0.3890\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.39424\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.6676 - acc: 0.3755 - val_loss: 1.6024 - val_acc: 0.3966\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.39424 to 0.39664, saving model to ../emotion_detector_models/model_v6_final.hdf5\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.6671 - acc: 0.3731 - val_loss: 1.6475 - val_acc: 0.3884\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.39664\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.6630 - acc: 0.3777 - val_loss: 1.6352 - val_acc: 0.3801\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.39664\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.6604 - acc: 0.3781 - val_loss: 1.5900 - val_acc: 0.3957\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.39664\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 1.6630 - acc: 0.3748 - val_loss: 1.6444 - val_acc: 0.3960\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.39664\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 1.6579 - acc: 0.3776 - val_loss: 1.6520 - val_acc: 0.3948\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.39664\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 1.6618 - acc: 0.3764 - val_loss: 1.5716 - val_acc: 0.3930\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.39664\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 1.6610 - acc: 0.3780 - val_loss: 1.6008 - val_acc: 0.3882\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.39664\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 14s 252ms/step - loss: 1.6530 - acc: 0.3822 - val_loss: 1.6536 - val_acc: 0.3870\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.39664\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.6590 - acc: 0.3759 - val_loss: 1.6725 - val_acc: 0.3923\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.39664\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 1.6617 - acc: 0.3778 - val_loss: 1.6080 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.39664 to 0.39739, saving model to ../emotion_detector_models/model_v6_final.hdf5\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6551 - acc: 0.3832 - val_loss: 1.6146 - val_acc: 0.3971\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.39739\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 14s 256ms/step - loss: 1.6541 - acc: 0.3776 - val_loss: 1.6135 - val_acc: 0.3792\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.39739\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 15s 271ms/step - loss: 1.6534 - acc: 0.3810 - val_loss: 1.6578 - val_acc: 0.3872\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.39739\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 1.6542 - acc: 0.3812 - val_loss: 1.6181 - val_acc: 0.3912\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.39739\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.6565 - acc: 0.3816 - val_loss: 1.6103 - val_acc: 0.4010\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.39739 to 0.40099, saving model to ../emotion_detector_models/model_v6_final.hdf5\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 1.6533 - acc: 0.3760 - val_loss: 1.6593 - val_acc: 0.3843\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.40099\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.6505 - acc: 0.3788 - val_loss: 1.5976 - val_acc: 0.3990\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.40099\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 1.6522 - acc: 0.3808 - val_loss: 1.6146 - val_acc: 0.3890\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.40099\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.6496 - acc: 0.3803 - val_loss: 1.6074 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.40099\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.6467 - acc: 0.3840 - val_loss: 1.6102 - val_acc: 0.3984\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.40099\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 1.6527 - acc: 0.3815 - val_loss: 1.5869 - val_acc: 0.3966\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.40099\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 1.6456 - acc: 0.3828 - val_loss: 1.6643 - val_acc: 0.3885\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.40099\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.6411 - acc: 0.3840 - val_loss: 1.6299 - val_acc: 0.3879\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.40099\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6496 - acc: 0.3837 - val_loss: 1.6648 - val_acc: 0.3906\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.40099\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.6504 - acc: 0.3859 - val_loss: 1.6358 - val_acc: 0.4002\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.40099\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 1.6440 - acc: 0.3872 - val_loss: 1.2369 - val_acc: 0.3993\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.40099\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 15s 259ms/step - loss: 1.6414 - acc: 0.3867 - val_loss: 1.5627 - val_acc: 0.3927\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.40099\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 15s 271ms/step - loss: 1.6432 - acc: 0.3846 - val_loss: 1.6363 - val_acc: 0.3924\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.40099\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 14s 256ms/step - loss: 1.6530 - acc: 0.3805 - val_loss: 1.6655 - val_acc: 0.3959\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.40099\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 14s 250ms/step - loss: 1.6493 - acc: 0.3824 - val_loss: 1.6063 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.40099\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6453 - acc: 0.3853 - val_loss: 1.6303 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.40099\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 1.6488 - acc: 0.3805 - val_loss: 1.5686 - val_acc: 0.3893\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.40099\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6435 - acc: 0.3831 - val_loss: 1.6064 - val_acc: 0.3878\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.40099\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 1.6385 - acc: 0.3853 - val_loss: 1.5709 - val_acc: 0.3996\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.40099\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 1.6413 - acc: 0.3854 - val_loss: 1.6974 - val_acc: 0.3950\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.40099\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 14s 250ms/step - loss: 1.6379 - acc: 0.3866 - val_loss: 1.5792 - val_acc: 0.3935\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.40099\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 1.6383 - acc: 0.3849 - val_loss: 1.6145 - val_acc: 0.3981\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.40099\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 14s 248ms/step - loss: 1.6380 - acc: 0.3886 - val_loss: 1.6461 - val_acc: 0.3968\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.40099\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.6423 - acc: 0.3853 - val_loss: 1.6512 - val_acc: 0.3957\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.40099\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 1.6434 - acc: 0.3887 - val_loss: 1.6323 - val_acc: 0.3948\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.40099\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.6360 - acc: 0.3877 - val_loss: 1.7042 - val_acc: 0.3989\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.40099\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 1.6400 - acc: 0.3873 - val_loss: 1.6372 - val_acc: 0.3993\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.40099\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 15s 265ms/step - loss: 1.6315 - acc: 0.3854 - val_loss: 1.5560 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.40099\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 15s 261ms/step - loss: 1.6416 - acc: 0.3872 - val_loss: 1.5735 - val_acc: 0.3954\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.40099\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6397 - acc: 0.3877 - val_loss: 1.5901 - val_acc: 0.3960\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.40099\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 1.6354 - acc: 0.3921 - val_loss: 1.6079 - val_acc: 0.3860\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.40099\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 15s 260ms/step - loss: 1.6380 - acc: 0.3866 - val_loss: 1.5506 - val_acc: 0.4103\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.40099 to 0.41029, saving model to ../emotion_detector_models/model_v6_final.hdf5\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 1.6384 - acc: 0.3892 - val_loss: 1.5567 - val_acc: 0.3878\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.41029\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 14s 250ms/step - loss: 1.6377 - acc: 0.3861 - val_loss: 1.5586 - val_acc: 0.4047\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.41029\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 1.6356 - acc: 0.3918 - val_loss: 1.5757 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.41029\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6372 - acc: 0.3895 - val_loss: 1.5833 - val_acc: 0.3966\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.41029\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 1.6353 - acc: 0.3896 - val_loss: 1.6187 - val_acc: 0.3987\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.41029\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 15s 261ms/step - loss: 1.6345 - acc: 0.3903 - val_loss: 1.5803 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.41029\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 1.6327 - acc: 0.3879 - val_loss: 1.6178 - val_acc: 0.3984\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.41029\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 1.6300 - acc: 0.3899 - val_loss: 1.5392 - val_acc: 0.4019\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.41029\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 1.6267 - acc: 0.3890 - val_loss: 1.2111 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.41029\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 14s 252ms/step - loss: 1.6282 - acc: 0.3899 - val_loss: 1.5829 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.41029\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 14s 255ms/step - loss: 1.6334 - acc: 0.3884 - val_loss: 1.6362 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.41029\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 1.6288 - acc: 0.3898 - val_loss: 1.6253 - val_acc: 0.3963\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.41029\n",
      "Epoch 64/100\n",
      "28/56 [==============>...............] - ETA: 5s - loss: 1.6226 - acc: 0.3961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cff4aa6fa47d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             validation_steps=nb_validation_samples // batch_size)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# plot_model_history(model_info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_weights('../emotion_detector_models/model_v6_71+83.hdf5')\n",
    "filepath = os.path.join(\"../emotion_detector_models/model_v6_final.hdf5\")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                             monitor='val_acc',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             mode='max')\n",
    "callbacks = [checkpoint]\n",
    "model.compile(loss='categorical_crossentropy',\\\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['acc'])\n",
    "nb_train_samples = train.shape[0]\n",
    "nb_validation_samples = val.shape[0]\n",
    "epochs = 100\n",
    "model_info = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# plot_model_history(model_info)\n",
    "# model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_info.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_info.history['loss'])\n",
    "plt.plot(model_info.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoblieNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 32\n",
    "\n",
    "train_data_dir = '../fer2013/train'\n",
    "validation_data_dir = '../fer2013/validation'\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 30,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 49, 49, 1)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 24, 24, 32)   288         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 24, 24, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 24, 24, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 24, 24, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 24, 24, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 24, 24, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 24, 24, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 24, 24, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 24, 24, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 24, 24, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 24, 24, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 25, 25, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 12, 12, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 12, 12, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 12, 12, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 12, 12, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 12, 12, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 12, 12, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 12, 12, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 12, 12, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 12, 12, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 12, 12, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 12, 12, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 12, 12, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 12, 12, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 12, 12, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 12, 12, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 12, 12, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 12, 12, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 13, 13, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 6, 6, 144)    1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 6, 6, 144)    576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 6, 6, 144)    0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 6, 6, 32)     4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 6, 6, 32)     128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 6, 6, 192)    6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 6, 6, 192)    768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 6, 6, 192)    0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 6, 6, 192)    1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 6, 6, 192)    768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 6, 6, 192)    0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 6, 6, 32)     6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 6, 6, 32)     128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 6, 6, 32)     0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 6, 6, 192)    6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 6, 6, 192)    768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 6, 6, 192)    0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 6, 6, 192)    1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 6, 6, 192)    768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 6, 6, 192)    0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 6, 6, 32)     6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 6, 6, 32)     128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 6, 6, 32)     0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 6, 6, 192)    6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 6, 6, 192)    768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 6, 6, 192)    0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 7, 7, 192)    0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 3, 3, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 3, 3, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 3, 3, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 3, 3, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 3, 3, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 3, 3, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 3, 3, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 3, 3, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 3, 3, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 3, 3, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 3, 3, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 3, 3, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 3, 3, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 3, 3, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 3, 3, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 3, 3, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 3, 3, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 3, 3, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 3, 3, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 3, 3, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 3, 3, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 3, 3, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 3, 3, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 3, 3, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 3, 3, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 3, 3, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 3, 3, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 3, 3, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 3, 3, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 3, 3, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 3, 3, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 3, 3, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 3, 3, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 3, 3, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 3, 3, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 3, 3, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 3, 3, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 3, 3, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 3, 3, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 3, 3, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 3, 3, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 3, 3, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 3, 3, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 3, 3, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 3, 3, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 3, 3, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 3, 3, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 3, 3, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 3, 3, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 3, 3, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 3, 3, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 3, 3, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 3, 3, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 3, 3, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 3, 3, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 3, 3, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 3, 3, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 3, 3, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 3, 3, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 3, 3, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 3, 3, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 5, 5, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 2, 2, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 2, 2, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 2, 2, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 2, 2, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 2, 2, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 2, 2, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 2, 2, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 2, 2, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 2, 2, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 2, 2, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 2, 2, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 2, 2, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 2, 2, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 2, 2, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 2, 2, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 2, 2, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 2, 2, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 2, 2, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 2, 2, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 2, 2, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 2, 2, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 2, 2, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 2, 2, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 2, 2, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 2, 2, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 2, 2, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 2, 2, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 2, 2, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 2, 2, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 2, 2, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 2, 2, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,408\n",
      "Trainable params: 2,223,296\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# or we can just load pretrained model\n",
    "model = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(img_rows,img_cols,1), alpha=1.0,\\\n",
    "                        include_top=False, weights=None, input_tensor=None,\\\n",
    "                                            pooling=None, classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 49, 49, 1)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 24, 24, 32)   288         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 24, 24, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 24, 24, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 24, 24, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 24, 24, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 24, 24, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 24, 24, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 24, 24, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 24, 24, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 24, 24, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 24, 24, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 25, 25, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 12, 12, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 12, 12, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 12, 12, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 12, 12, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 12, 12, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 12, 12, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 12, 12, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 12, 12, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 12, 12, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 12, 12, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 12, 12, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 12, 12, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 12, 12, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 12, 12, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 12, 12, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 12, 12, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 12, 12, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 13, 13, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 6, 6, 144)    1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 6, 6, 144)    576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 6, 6, 144)    0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 6, 6, 32)     4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 6, 6, 32)     128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 6, 6, 192)    6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 6, 6, 192)    768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 6, 6, 192)    0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 6, 6, 192)    1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 6, 6, 192)    768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 6, 6, 192)    0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 6, 6, 32)     6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 6, 6, 32)     128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 6, 6, 32)     0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 6, 6, 192)    6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 6, 6, 192)    768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 6, 6, 192)    0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 6, 6, 192)    1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 6, 6, 192)    768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 6, 6, 192)    0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 6, 6, 32)     6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 6, 6, 32)     128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 6, 6, 32)     0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 6, 6, 192)    6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 6, 6, 192)    768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 6, 6, 192)    0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 7, 7, 192)    0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 3, 3, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 3, 3, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 3, 3, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 3, 3, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 3, 3, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 3, 3, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 3, 3, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 3, 3, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 3, 3, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 3, 3, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 3, 3, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 3, 3, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 3, 3, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 3, 3, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 3, 3, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 3, 3, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 3, 3, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 3, 3, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 3, 3, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 3, 3, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 3, 3, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 3, 3, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 3, 3, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 3, 3, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 3, 3, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 3, 3, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 3, 3, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 3, 3, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 3, 3, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 3, 3, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 3, 3, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 3, 3, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 3, 3, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 3, 3, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 3, 3, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 3, 3, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 3, 3, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 3, 3, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 3, 3, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 3, 3, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 3, 3, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 3, 3, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 3, 3, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 3, 3, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 3, 3, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 3, 3, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 3, 3, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 3, 3, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 3, 3, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 3, 3, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 3, 3, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 3, 3, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 3, 3, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 3, 3, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 3, 3, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 3, 3, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 3, 3, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 3, 3, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 3, 3, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 3, 3, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 3, 3, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 5, 5, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 2, 2, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 2, 2, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 2, 2, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 2, 2, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 2, 2, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 2, 2, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 2, 2, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 2, 2, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 2, 2, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 2, 2, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 2, 2, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 2, 2, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 2, 2, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 2, 2, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 2, 2, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 2, 2, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 2, 2, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 2, 2, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 2, 2, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 2, 2, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 2, 2, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 2, 2, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 2, 2, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 2, 2, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 2, 2, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 2, 2, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 2, 2, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 2, 2, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 2, 2, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 2, 2, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 2, 2, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 5120)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          1310976     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 7)            1799        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,570,183\n",
      "Trainable params: 3,536,071\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256)(x)\n",
    "x = Dense(7)(x)\n",
    "\n",
    "model = Model(model.input, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "897/897 [==============================] - 52s 58ms/step - loss: 8.5699 - acc: 0.2489 - val_loss: 8.0590 - val_acc: 0.2447\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24470, saving model to ../emotion_detector_models/model_mobile_1.hdf5\n",
      "Epoch 2/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.6645 - acc: 0.2506 - val_loss: 10.5775 - val_acc: 0.2497\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.24470 to 0.24972, saving model to ../emotion_detector_models/model_mobile_2.hdf5\n",
      "Epoch 3/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.7077 - acc: 0.2507 - val_loss: 9.0664 - val_acc: 0.2493\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.24972\n",
      "Epoch 4/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.6729 - acc: 0.2487 - val_loss: 9.0664 - val_acc: 0.2453\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.24972\n",
      "Epoch 5/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.6314 - acc: 0.2308 - val_loss: 7.5554 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.24972\n",
      "Epoch 6/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.1309 - acc: 0.0867 - val_loss: 4.5332 - val_acc: 0.1180\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.24972\n",
      "Epoch 7/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.0839 - acc: 0.0859 - val_loss: 7.5554 - val_acc: 0.2369\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.24972\n",
      "Epoch 8/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.0174 - acc: 0.0860 - val_loss: 6.0443 - val_acc: 0.2391\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.24972\n",
      "Epoch 9/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.0737 - acc: 0.0854 - val_loss: 5.5406 - val_acc: 0.1965\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.24972\n",
      "Epoch 10/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.0123 - acc: 0.0843 - val_loss: 7.5554 - val_acc: 0.1270\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.24972\n",
      "Epoch 11/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.0808 - acc: 0.0871 - val_loss: 9.0664 - val_acc: 0.1013\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.24972\n",
      "Epoch 12/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 7.9354 - acc: 0.0872 - val_loss: 7.5554 - val_acc: 0.0882\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.24972\n",
      "Epoch 13/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.0571 - acc: 0.0882 - val_loss: 8.0590 - val_acc: 0.0845\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.24972\n",
      "Epoch 14/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.0194 - acc: 0.0869 - val_loss: 7.0517 - val_acc: 0.0823\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.24972\n",
      "Epoch 15/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 7.9499 - acc: 0.0896 - val_loss: 8.0590 - val_acc: 0.0783\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.24972\n",
      "Epoch 16/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.0354 - acc: 0.0868 - val_loss: 8.0590 - val_acc: 0.0837\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.24972\n",
      "Epoch 17/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.0687 - acc: 0.0848 - val_loss: 9.5701 - val_acc: 0.0755\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.24972\n",
      "Epoch 18/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 7.9972 - acc: 0.0890 - val_loss: 7.0517 - val_acc: 0.0862\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.24972\n",
      "Epoch 19/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2344 - acc: 0.2188 - val_loss: 7.0517 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.24972\n",
      "Epoch 20/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2573 - acc: 0.2515 - val_loss: 10.5775 - val_acc: 0.2553\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.24972 to 0.25530, saving model to ../emotion_detector_models/model_mobile_20.hdf5\n",
      "Epoch 21/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2883 - acc: 0.2511 - val_loss: 9.0664 - val_acc: 0.2532\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.25530\n",
      "Epoch 22/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2310 - acc: 0.2514 - val_loss: 8.5627 - val_acc: 0.2386\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.25530\n",
      "Epoch 23/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.1949 - acc: 0.2520 - val_loss: 8.0590 - val_acc: 0.2414\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.25530\n",
      "Epoch 24/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2921 - acc: 0.2509 - val_loss: 7.5554 - val_acc: 0.2570\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.25530 to 0.25698, saving model to ../emotion_detector_models/model_mobile_24.hdf5\n",
      "Epoch 25/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.3188 - acc: 0.2507 - val_loss: 8.5627 - val_acc: 0.2454\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.25698\n",
      "Epoch 26/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.1993 - acc: 0.2511 - val_loss: 8.0590 - val_acc: 0.2447\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.25698\n",
      "Epoch 27/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2111 - acc: 0.2520 - val_loss: 8.0590 - val_acc: 0.2487\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.25698\n",
      "Epoch 28/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2437 - acc: 0.2511 - val_loss: 6.5480 - val_acc: 0.2475\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.25698\n",
      "Epoch 29/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.3389 - acc: 0.2507 - val_loss: 6.5480 - val_acc: 0.2538\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.25698\n",
      "Epoch 30/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2394 - acc: 0.2522 - val_loss: 8.0590 - val_acc: 0.2478\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.25698\n",
      "Epoch 31/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2062 - acc: 0.2510 - val_loss: 8.5627 - val_acc: 0.2389\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.25698\n",
      "Epoch 32/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2963 - acc: 0.2512 - val_loss: 10.5775 - val_acc: 0.2469\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.25698\n",
      "Epoch 33/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.1748 - acc: 0.2508 - val_loss: 10.5775 - val_acc: 0.2476\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.25698\n",
      "Epoch 34/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2939 - acc: 0.2519 - val_loss: 7.0517 - val_acc: 0.2486\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.25698\n",
      "Epoch 35/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2141 - acc: 0.2507 - val_loss: 6.5480 - val_acc: 0.2454\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.25698\n",
      "Epoch 36/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2880 - acc: 0.2523 - val_loss: 7.5554 - val_acc: 0.2475\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.25698\n",
      "Epoch 37/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2655 - acc: 0.2507 - val_loss: 6.5480 - val_acc: 0.2412\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.25698\n",
      "Epoch 38/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.2089 - acc: 0.2529 - val_loss: 8.0590 - val_acc: 0.2525\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.25698\n",
      "Epoch 39/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2774 - acc: 0.2493 - val_loss: 8.0590 - val_acc: 0.2558\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.25698\n",
      "Epoch 40/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2001 - acc: 0.2532 - val_loss: 6.5480 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.25698\n",
      "Epoch 41/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.2765 - acc: 0.2486 - val_loss: 9.5701 - val_acc: 0.2490\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.25698\n",
      "Epoch 42/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2194 - acc: 0.2521 - val_loss: 7.0517 - val_acc: 0.2453\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.25698\n",
      "Epoch 43/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2695 - acc: 0.2510 - val_loss: 9.0664 - val_acc: 0.2487\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.25698\n",
      "Epoch 44/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.2723 - acc: 0.2524 - val_loss: 7.0517 - val_acc: 0.2444\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.25698\n",
      "Epoch 45/150\n",
      "897/897 [==============================] - 46s 52ms/step - loss: 8.2984 - acc: 0.2504 - val_loss: 9.0664 - val_acc: 0.2456\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.25698\n",
      "Epoch 46/150\n",
      "897/897 [==============================] - 46s 51ms/step - loss: 8.3324 - acc: 0.2518 - val_loss: 9.0664 - val_acc: 0.2480\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.25698\n",
      "Epoch 47/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2424 - acc: 0.2506 - val_loss: 7.0517 - val_acc: 0.2428\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.25698\n",
      "Epoch 48/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2532 - acc: 0.2523 - val_loss: 9.0664 - val_acc: 0.2469\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.25698\n",
      "Epoch 49/150\n",
      "897/897 [==============================] - 48s 54ms/step - loss: 8.3102 - acc: 0.2504 - val_loss: 8.0590 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.25698\n",
      "Epoch 50/150\n",
      "897/897 [==============================] - 49s 54ms/step - loss: 8.2397 - acc: 0.2515 - val_loss: 8.0590 - val_acc: 0.2494\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.25698\n",
      "Epoch 51/150\n",
      "897/897 [==============================] - 49s 54ms/step - loss: 8.2242 - acc: 0.2511 - val_loss: 8.5627 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.25698\n",
      "Epoch 52/150\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 8.2527 - acc: 0.2525 - val_loss: 10.0738 - val_acc: 0.2539\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.25698\n",
      "Epoch 53/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2059 - acc: 0.2499 - val_loss: 8.0590 - val_acc: 0.2459\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.25698\n",
      "Epoch 54/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2210 - acc: 0.2520 - val_loss: 8.5627 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.25698\n",
      "Epoch 55/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2429 - acc: 0.2504 - val_loss: 10.5775 - val_acc: 0.2487\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.25698\n",
      "Epoch 56/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2444 - acc: 0.2511 - val_loss: 7.0517 - val_acc: 0.2469\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.25698\n",
      "Epoch 57/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2351 - acc: 0.2528 - val_loss: 7.5554 - val_acc: 0.2459\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.25698\n",
      "Epoch 58/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 8.2310 - acc: 0.2508 - val_loss: 9.0664 - val_acc: 0.2517\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.25698\n",
      "Epoch 59/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2327 - acc: 0.2517 - val_loss: 8.5627 - val_acc: 0.2431\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.25698\n",
      "Epoch 60/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2740 - acc: 0.2511 - val_loss: 7.0517 - val_acc: 0.2503\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.25698\n",
      "Epoch 61/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 8.3109 - acc: 0.2520 - val_loss: 6.0443 - val_acc: 0.2456\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.25698\n",
      "Epoch 62/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2793 - acc: 0.2498 - val_loss: 6.0443 - val_acc: 0.2478\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.25698\n",
      "Epoch 63/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.1569 - acc: 0.2527 - val_loss: 7.5554 - val_acc: 0.2448\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.25698\n",
      "Epoch 64/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 8.2369 - acc: 0.2503 - val_loss: 6.5480 - val_acc: 0.2439\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.25698\n",
      "Epoch 65/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 8.2529 - acc: 0.2524 - val_loss: 7.5554 - val_acc: 0.2476\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.25698\n",
      "Epoch 66/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 8.2487 - acc: 0.2505 - val_loss: 7.5554 - val_acc: 0.2503\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.25698\n",
      "Epoch 67/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 8.2023 - acc: 0.2510 - val_loss: 8.0590 - val_acc: 0.2398\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.25698\n",
      "Epoch 68/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 5.5412 - acc: 0.2154 - val_loss: 1.1921e-07 - val_acc: 0.1339\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.25698\n",
      "Epoch 69/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1362\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.25698\n",
      "Epoch 70/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1379 - val_loss: 1.1921e-07 - val_acc: 0.1292\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.25698\n",
      "Epoch 71/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1406 - val_loss: 1.1921e-07 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.25698\n",
      "Epoch 72/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1391 - val_loss: 1.1921e-07 - val_acc: 0.1381\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.25698\n",
      "Epoch 73/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1395 - val_loss: 1.1921e-07 - val_acc: 0.1319\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.25698\n",
      "Epoch 74/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1377 - val_loss: 1.1921e-07 - val_acc: 0.1350\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.25698\n",
      "Epoch 75/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1391 - val_loss: 1.1921e-07 - val_acc: 0.1241\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.25698\n",
      "Epoch 76/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1390 - val_loss: 1.1921e-07 - val_acc: 0.1362\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.25698\n",
      "Epoch 77/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1339\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.25698\n",
      "Epoch 78/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1401 - val_loss: 1.1921e-07 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.25698\n",
      "Epoch 79/150\n",
      "897/897 [==============================] - 45s 51ms/step - loss: 1.1921e-07 - acc: 0.1384 - val_loss: 1.1921e-07 - val_acc: 0.1384\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.25698\n",
      "Epoch 80/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1391 - val_loss: 1.1921e-07 - val_acc: 0.1334\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.25698\n",
      "Epoch 81/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1392 - val_loss: 1.1921e-07 - val_acc: 0.1350\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.25698\n",
      "Epoch 82/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1393 - val_loss: 1.1921e-07 - val_acc: 0.1334\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.25698\n",
      "Epoch 83/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1398 - val_loss: 1.1921e-07 - val_acc: 0.1345\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.25698\n",
      "Epoch 84/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1388 - val_loss: 1.1921e-07 - val_acc: 0.1356\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.25698\n",
      "Epoch 85/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1390 - val_loss: 1.1921e-07 - val_acc: 0.1317\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.25698\n",
      "Epoch 86/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1387 - val_loss: 1.1921e-07 - val_acc: 0.1323\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.25698\n",
      "Epoch 87/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1399 - val_loss: 1.1921e-07 - val_acc: 0.1305\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.25698\n",
      "Epoch 88/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.25698\n",
      "Epoch 89/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1394 - val_loss: 1.1921e-07 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.25698\n",
      "Epoch 90/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1376 - val_loss: 1.1921e-07 - val_acc: 0.1381\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.25698\n",
      "Epoch 91/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1388 - val_loss: 1.1921e-07 - val_acc: 0.1308\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.25698\n",
      "Epoch 92/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1399 - val_loss: 1.1921e-07 - val_acc: 0.1281\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.25698\n",
      "Epoch 93/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1383 - val_loss: 1.1921e-07 - val_acc: 0.1342\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.25698\n",
      "Epoch 94/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1402 - val_loss: 1.1921e-07 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.25698\n",
      "Epoch 95/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1384 - val_loss: 1.1921e-07 - val_acc: 0.1204\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.25698\n",
      "Epoch 96/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1394 - val_loss: 1.1921e-07 - val_acc: 0.1417\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.25698\n",
      "Epoch 97/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1389 - val_loss: 1.1921e-07 - val_acc: 0.1350\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.25698\n",
      "Epoch 98/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.25698\n",
      "Epoch 99/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1402 - val_loss: 1.1921e-07 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.25698\n",
      "Epoch 100/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1384 - val_loss: 1.1921e-07 - val_acc: 0.1353\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.25698\n",
      "Epoch 101/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1400 - val_loss: 1.1921e-07 - val_acc: 0.1359\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.25698\n",
      "Epoch 102/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1374 - val_loss: 1.1921e-07 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.25698\n",
      "Epoch 103/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1399 - val_loss: 1.1921e-07 - val_acc: 0.1261\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.25698\n",
      "Epoch 104/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1378 - val_loss: 1.1921e-07 - val_acc: 0.1387\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.25698\n",
      "Epoch 105/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.25698\n",
      "Epoch 106/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1403 - val_loss: 1.1921e-07 - val_acc: 0.1415\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.25698\n",
      "Epoch 107/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1393 - val_loss: 1.1921e-07 - val_acc: 0.1317\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.25698\n",
      "Epoch 108/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1398 - val_loss: 1.1921e-07 - val_acc: 0.1325\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.25698\n",
      "Epoch 109/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1389 - val_loss: 1.1921e-07 - val_acc: 0.1336\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.25698\n",
      "Epoch 110/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1389 - val_loss: 1.1921e-07 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.25698\n",
      "Epoch 111/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1388 - val_loss: 1.1921e-07 - val_acc: 0.1353\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.25698\n",
      "Epoch 112/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1388 - val_loss: 1.1921e-07 - val_acc: 0.1309\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.25698\n",
      "Epoch 113/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1391 - val_loss: 1.1921e-07 - val_acc: 0.1367\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.25698\n",
      "Epoch 114/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1405 - val_loss: 1.1921e-07 - val_acc: 0.1378\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.25698\n",
      "Epoch 115/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1378 - val_loss: 1.1921e-07 - val_acc: 0.1311\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.25698\n",
      "Epoch 116/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1394 - val_loss: 1.1921e-07 - val_acc: 0.1300\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.25698\n",
      "Epoch 117/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1393 - val_loss: 1.1921e-07 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.25698\n",
      "Epoch 118/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1383 - val_loss: 1.1921e-07 - val_acc: 0.1378\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.25698\n",
      "Epoch 119/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1300\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.25698\n",
      "Epoch 120/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1390 - val_loss: 1.1921e-07 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.25698\n",
      "Epoch 121/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1397 - val_loss: 1.1921e-07 - val_acc: 0.1348\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.25698\n",
      "Epoch 122/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1388 - val_loss: 1.1921e-07 - val_acc: 0.1306\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.25698\n",
      "Epoch 123/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1387 - val_loss: 1.1921e-07 - val_acc: 0.1401\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.25698\n",
      "Epoch 124/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1339\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.25698\n",
      "Epoch 125/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1396 - val_loss: 1.1921e-07 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.25698\n",
      "Epoch 126/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1392 - val_loss: 1.1921e-07 - val_acc: 0.1403\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.25698\n",
      "Epoch 127/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1397 - val_loss: 1.1921e-07 - val_acc: 0.1345\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.25698\n",
      "Epoch 128/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 45s 51ms/step - loss: 1.1921e-07 - acc: 0.1377 - val_loss: 1.1921e-07 - val_acc: 0.1275\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.25698\n",
      "Epoch 129/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1404 - val_loss: 1.1921e-07 - val_acc: 0.1311\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.25698\n",
      "Epoch 130/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1376 - val_loss: 1.1921e-07 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.25698\n",
      "Epoch 131/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1391 - val_loss: 1.1921e-07 - val_acc: 0.1331\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.25698\n",
      "Epoch 132/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1406 - val_loss: 1.1921e-07 - val_acc: 0.1364\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.25698\n",
      "Epoch 133/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1385 - val_loss: 1.1921e-07 - val_acc: 0.1266\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.25698\n",
      "Epoch 134/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1394 - val_loss: 1.1921e-07 - val_acc: 0.1300\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.25698\n",
      "Epoch 135/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1379 - val_loss: 1.1921e-07 - val_acc: 0.1395\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.25698\n",
      "Epoch 136/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1389 - val_loss: 1.1921e-07 - val_acc: 0.1345\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.25698\n",
      "Epoch 137/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1417 - val_loss: 1.1921e-07 - val_acc: 0.1291\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.25698\n",
      "Epoch 138/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1373 - val_loss: 1.1921e-07 - val_acc: 0.1412\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.25698\n",
      "Epoch 139/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1415 - val_loss: 1.1921e-07 - val_acc: 0.1305\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.25698\n",
      "Epoch 140/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1387 - val_loss: 1.1921e-07 - val_acc: 0.1286\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.25698\n",
      "Epoch 141/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1376 - val_loss: 1.1921e-07 - val_acc: 0.1356\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.25698\n",
      "Epoch 142/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1403 - val_loss: 1.1921e-07 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.25698\n",
      "Epoch 143/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1391 - val_loss: 1.1921e-07 - val_acc: 0.1334\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.25698\n",
      "Epoch 144/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1371 - val_loss: 1.1921e-07 - val_acc: 0.1297\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.25698\n",
      "Epoch 145/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1393 - val_loss: 1.1921e-07 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.25698\n",
      "Epoch 146/150\n",
      "897/897 [==============================] - 44s 50ms/step - loss: 1.1921e-07 - acc: 0.1398 - val_loss: 1.1921e-07 - val_acc: 0.1339\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.25698\n",
      "Epoch 147/150\n",
      "897/897 [==============================] - 44s 49ms/step - loss: 1.1921e-07 - acc: 0.1401 - val_loss: 1.1921e-07 - val_acc: 0.1378\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.25698\n",
      "Epoch 148/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1389 - val_loss: 1.1921e-07 - val_acc: 0.1306\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.25698\n",
      "Epoch 149/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1398 - val_loss: 1.1921e-07 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.25698\n",
      "Epoch 150/150\n",
      "897/897 [==============================] - 45s 50ms/step - loss: 1.1921e-07 - acc: 0.1377 - val_loss: 1.1921e-07 - val_acc: 0.1412\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.25698\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(\"../emotion_detector_models/model_mobile_{epoch}.hdf5\")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                             monitor='val_acc',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             mode='max')\n",
    "callbacks = [checkpoint]\n",
    "model.compile(loss='categorical_crossentropy',\\\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['acc'])\n",
    "nb_train_samples = 28709\n",
    "nb_validation_samples = 3589\n",
    "epochs = 150\n",
    "model_info = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# plot_model_history(model_info)\n",
    "# model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fbfdafab080>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fbfdafab4e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfdafab828>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfdafaba20>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfdafab7f0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbfdafab9b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc063c95b70>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfdafa1a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfdafb2438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc063c37470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc063ba8b70>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc063b08710>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc063aadb70>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fc063b44908>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fc063a0ef28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc0639e1390>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc0639fdb00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc06395bc50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc0639bc0b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc0639a7080>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc0638b6c50>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc06381f828>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fc063505da0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc063548f28>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc0634da240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc063459eb8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc06349eb00>,\n",
       " <keras.layers.merge.Add at 0x7fc0634f96d8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc0633e73c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc063379978>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc0633ad780>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fc0632a11d0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fc063280ba8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc063217828>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc063217978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc063195cf8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc0631d9da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fc063235cf8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fc0630e61d0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc063122710>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbfd84e9630>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfd845e748>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fc062fff9b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfd838d630>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfd8440e10>,\n",
       " <keras.layers.merge.Add at 0x7fbfd83b1cc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfd8352f28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfd832e0b8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfd836fcc0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbfd81d3898>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfd819a4a8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfd82c3c50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfd81b5400>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfd817a828>,\n",
       " <keras.layers.merge.Add at 0x7fbfd80f0a20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfd806b048>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfd804dfd0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfd8092f28>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fbfb06fd5f8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbfb07b3f60>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb06c0358>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfb06c0550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfb0670438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb06a18d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfb06147b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb05f4d30>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfb053ec88>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbfb0439588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb03fdd68>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfb05293c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfb037cf28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb03dbf98>,\n",
       " <keras.layers.merge.Add at 0x7fbfb041c0b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfb02cfeb8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb032f7b8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfb0370cf8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbfb02603c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb0207fd0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbfb019bf98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbfb0119c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb00f90b8>,\n",
       " <keras.layers.merge.Add at 0x7fbfb013fac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9c7fa6d8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbfb0070ef0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9c7a0d68>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf9c747fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c724128>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9c69b6a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9c615470>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c676f28>,\n",
       " <keras.layers.merge.Add at 0x7fbf9c6b9828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9c53b438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c56fe10>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9c4e27b8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf9c49e128>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c447da0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9c3d7198>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9c300828>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c3babe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9c3f61d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c21cf98>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9c2e8358>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf9c19feb8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c1fc7b8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9c1be7b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9c040438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9c0f08d0>,\n",
       " <keras.layers.merge.Add at 0x7fbf9c0647b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf947e2128>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf94787978>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf947c9048>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf946446d8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf9467fda0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf9473aa58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf9462a588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf945ee390>,\n",
       " <keras.layers.merge.Add at 0x7fbf9462a390>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf944e3470>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf944c3f28>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf94503e48>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fbf94383400>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf94435278>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf94350358>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf94350be0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf943657b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf94328438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf94365588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf941feeb8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf941b0dd8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf941cea90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf940bdac8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf940e6fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf6c7d4d30>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf94065da0>,\n",
       " <keras.layers.merge.Add at 0x7fbf94086b70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf6c6c2780>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c75ea58>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf6c7bcb00>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf6c6ac1d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c66d198>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf6c5e0780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf6c55f630>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c53ee80>,\n",
       " <keras.layers.merge.Add at 0x7fbf6c581908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf6c4024e0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c4b8978>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf6c49bf60>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x7fbf6c3e81d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c38bc18>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf6c31d7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf6c2488d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c2fcc88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fbf6c2be630>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7fbf6c168f98>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x7fbf6c231400>,\n",
       " <keras.layers.core.Flatten at 0x7fbf2d749320>,\n",
       " <keras.layers.core.Dropout at 0x7fbf2d749208>,\n",
       " <keras.layers.core.Dense at 0x7fbf2d749390>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
