{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Sample_Pic_OD/fer2013.csv')\n",
    "train = dataset[['emotion','pixels']][:28709]\n",
    "val = dataset[['emotion','pixels']][28709:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 2), (7178, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1da807e1828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train['pixels'][0]\n",
    "img = np.array(img.split(' ')).reshape(48,-1).astype('float')\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',\\\n",
    "            6:'Neutral'}\n",
    "# just save one file for test\n",
    "cv2.imwrite('../fer2013/train/{}/{}.jpg'.format(label_map[train['emotion'][0]], 1), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',\\\n",
    "            6:'Neutral'}\n",
    "for num, i in enumerate(train.index):\n",
    "    img = train['pixels'][i]\n",
    "    img = np.array(img.split(' ')).astype('float').reshape(48,-1)\n",
    "    label = train['emotion'][i]\n",
    "    cv2.imwrite('../fer2013/train/{}/{}.jpg'.format(label_map[label], num), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, i in enumerate(val.index):\n",
    "    img = val['pixels'][i]\n",
    "    img = np.array(img.split(' ')).astype('float').reshape(48,-1)\n",
    "    label = val['emotion'][i]\n",
    "    cv2.imwrite('../fer2013/validation/{}/{}.jpg'.format(label_map[label], num), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 512\n",
    "\n",
    "train_data_dir = '../fer2013/train'\n",
    "validation_data_dir = '../fer2013/validation'\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 30,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 7)           903       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 7)           791       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 241,950\n",
      "Trainable params: 241,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001),input_shape=(48,48,1)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(7, kernel_size=(1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# # model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(7, kernel_size=(4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can just load pretrained model\n",
    "model = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(img_rows,img_cols,3), alpha=1.0,\\\n",
    "                        include_top=True, weights='imagenet', input_tensor=None,\\\n",
    "                                            pooling=None, classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "56/56 [==============================] - 148s 3s/step - loss: 1.9715 - accuracy: 0.1375 - val_loss: 1.9689 - val_accuracy: 0.1412\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 143s 3s/step - loss: 1.9669 - accuracy: 0.1443 - val_loss: 1.9647 - val_accuracy: 0.1529\n",
      "Epoch 3/150\n",
      "56/56 [==============================] - 152s 3s/step - loss: 1.9630 - accuracy: 0.1478 - val_loss: 1.9611 - val_accuracy: 0.1606\n",
      "Epoch 4/150\n",
      "56/56 [==============================] - 151s 3s/step - loss: 1.9587 - accuracy: 0.1624 - val_loss: 1.9471 - val_accuracy: 0.1825\n",
      "Epoch 5/150\n",
      "56/56 [==============================] - 153s 3s/step - loss: 1.9429 - accuracy: 0.1867 - val_loss: 1.9396 - val_accuracy: 0.2083\n",
      "Epoch 6/150\n",
      "56/56 [==============================] - 147s 3s/step - loss: 1.9076 - accuracy: 0.2128 - val_loss: 1.8624 - val_accuracy: 0.2508\n",
      "Epoch 7/150\n",
      " 4/56 [=>............................] - ETA: 2:12 - loss: 1.8639 - accuracy: 0.2373"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-403740a697c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             validation_steps=nb_validation_samples // batch_size)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# plot_model_history(model_info)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(\"./emotion_detector_models/model_v6_{epoch}.hdf5\")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                             monitor='val_acc',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             mode='max')\n",
    "callbacks = [checkpoint]\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "nb_train_samples = 28709\n",
    "nb_validation_samples = 3589\n",
    "epochs = 150\n",
    "model_info = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# plot_model_history(model_info)\n",
    "# model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6386e20a689d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_info' is not defined"
     ]
    }
   ],
   "source": [
    "print(model_info.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_info.history['loss'])\n",
    "plt.plot(model_info.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
